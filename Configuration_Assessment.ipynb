{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AI5ozM2h2Nva"
   },
   "source": [
    "# Configuration Assessment Use Case\n",
    "\n",
    "In nearly every security incident, misconfiguration is either the root cause or a critical enabler. Today, most config assessments rely on static rule-matching engines that check config files or cloud settings against predefined rules. But these tools lack contextual understanding of how different components interact — they can't tell if a setting is safe for your environment.\n",
    "\n",
    "This use case focuses on an AI model that ingests configuration data across cloud, infra, app, and identity layers — and reasons over them to identify security misconfigurations, weak settings, and missing best practices.\n",
    "\n",
    "## Model used for this use case\n",
    "Both Instruct Model and Reasoning Model would be suitable for this task. In this example, we use the model via SageMaker endpoint for contextual configuration analysis.\n",
    "\n",
    "**Note**: Update the configuration variables below to match your deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Update these variables to match your SageMaker deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE THESE VARIABLES TO MATCH YOUR DEPLOYMENT\n",
    "endpoint_name = 'foundation-sec-8b-endpoint'  # Your SageMaker endpoint name\n",
    "aws_region = 'us-east-1'  # Your AWS region\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"Endpoint: {endpoint_name}\")\n",
    "print(f\"Region: {aws_region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The setup uses SageMaker endpoint instead of loading the model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import re\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Initialize SageMaker runtime client\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime', region_name=aws_region)\n",
    "\n",
    "print(f\"Connected to SageMaker endpoint: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation arguments for configuration analysis\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"temperature\": None,  # Deterministic for consistent analysis\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"do_sample\": False,\n",
    "    \"use_cache\": True,\n",
    "}\n",
    "\n",
    "print(\"Generation configuration:\")\n",
    "for key, value in generation_args.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(prompt):\n",
    "    \"\"\"Inference function using SageMaker endpoint for configuration analysis\"\"\"\n",
    "    \n",
    "    # Format the prompt for the reasoning model style\n",
    "    formatted_prompt = f\"User: {prompt}\\n\\nAssistant: Let me analyze this configuration step by step.\"\n",
    "    \n",
    "    # Prepare payload for SageMaker endpoint\n",
    "    payload = {\n",
    "        \"inputs\": formatted_prompt,\n",
    "        \"parameters\": generation_args\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = sagemaker_runtime.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType='application/json',\n",
    "            Body=json.dumps(payload)\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response['Body'].read().decode())\n",
    "        \n",
    "        # Handle different TGI response formats\n",
    "        if isinstance(result, list) and len(result) > 0:\n",
    "            generated_text = result[0].get('generated_text', '')\n",
    "        elif isinstance(result, dict):\n",
    "            generated_text = result.get('generated_text', str(result))\n",
    "        else:\n",
    "            generated_text = str(result)\n",
    "        \n",
    "        # Clean up the response (remove the original prompt if it's included)\n",
    "        if generated_text.startswith(formatted_prompt):\n",
    "            response_text = generated_text[len(formatted_prompt):].strip()\n",
    "        else:\n",
    "            response_text = generated_text.strip()\n",
    "            \n",
    "        # Remove any trailing special tokens\n",
    "        response_text = re.sub(r'<\\|.*?\\|>$', '', response_text).strip()\n",
    "        \n",
    "        return response_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking endpoint: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test the inference function\n",
    "test_response = inference(\"Test configuration analysis\")\n",
    "print(\"Test Response:\")\n",
    "print(test_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": \"-2XV1flWD-qM\""
   },
   "source": [
    "## Configuration Assessment\n",
    "\n",
    "Let's analyze different types of configurations for security issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": \"BY5Wyux1EhVQ\""
   },
   "source": [
    "### Example 1: Terraform Google Cloud Configuration\n",
    "\n",
    "Here's a mock Terraform configuration with potential security issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": \"Obe30-VYESs6\""
   },
   "outputs": [],
   "source": [
    "terraform_config = \"\"\"\n",
    "provider \"google\" {\n",
    "  project = \"my-project\"\n",
    "  region  = \"us-central1\"\n",
    "}\n",
    "\n",
    "resource \"google_compute_network\" \"default\" {\n",
    "  name                    = \"default-network\"\n",
    "  auto_create_subnetworks = true\n",
    "}\n",
    "\n",
    "resource \"google_compute_firewall\" \"allow_all_inbound\" {\n",
    "  name    = \"allow-all-inbound\"\n",
    "  network = google_compute_network.default.name\n",
    "\n",
    "  direction = \"INGRESS\"\n",
    "  priority  = 1000\n",
    "\n",
    "  allows {\n",
    "    protocol = \"tcp\"\n",
    "    ports    = [\"0-65535\"]\n",
    "  }\n",
    "\n",
    "  allows {\n",
    "    protocol = \"udp\"\n",
    "    ports    = [\"0-65535\"]\n",
    "  }\n",
    "\n",
    "  source_ranges = [\"0.0.0.0/0\"]\n",
    "\n",
    "  target_tags = [\"web\"]\n",
    "  description = \"Allow all inbound traffic from any IP on all ports\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Terraform configuration loaded for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_config_prompt(config_text, config_type=\"configuration\"):\n",
    "    return f\"\"\"You are a security auditor reviewing a {config_type} file for security issues.\n",
    "    \n",
    "    Go over the following configuration line-by-line and assess it for:\n",
    "    1. Security misconfigurations\n",
    "    2. Weak or deprecated settings\n",
    "    3. Missing best practices\n",
    "    4. Potential attack vectors\n",
    "    \n",
    "    ## CONFIGURATION\n",
    "    {config_text}\n",
    "    \n",
    "    For each issue found, provide:\n",
    "    - Detected misconfiguration or weakness\n",
    "    - Severity (Critical/High/Medium/Low)\n",
    "    - Security impact\n",
    "    - Recommended fix\n",
    "    - Code example of the fix (if applicable)\n",
    "    \n",
    "    Format your response with clear sections and be specific about security risks.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": \"7q9yZevyEi8b\""
   },
   "outputs": [],
   "source": [
    "print(\"=== TERRAFORM CONFIGURATION SECURITY ANALYSIS ===\")\n",
    "response = inference(make_config_prompt(terraform_config, \"Terraform\"))\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: SSH Configuration Analysis\n",
    "\n",
    "Let's analyze an SSH server configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_config = \"\"\"\n",
    "# SSH Server Configuration\n",
    "Port 22\n",
    "Protocol 2\n",
    "HostKey /etc/ssh/ssh_host_rsa_key\n",
    "HostKey /etc/ssh/ssh_host_ecdsa_key\n",
    "HostKey /etc/ssh/ssh_host_ed25519_key\n",
    "\n",
    "# Logging\n",
    "SyslogFacility AUTH\n",
    "LogLevel INFO\n",
    "\n",
    "# Authentication\n",
    "LoginGraceTime 120\n",
    "PermitRootLogin yes\n",
    "StrictModes yes\n",
    "MaxAuthTries 6\n",
    "MaxSessions 10\n",
    "\n",
    "# Password authentication\n",
    "PasswordAuthentication yes\n",
    "PermitEmptyPasswords no\n",
    "ChallengeResponseAuthentication no\n",
    "\n",
    "# Kerberos options\n",
    "KerberosAuthentication no\n",
    "KerberosOrLocalPasswd yes\n",
    "KerberosTicketCleanup yes\n",
    "\n",
    "# X11 forwarding\n",
    "X11Forwarding yes\n",
    "X11DisplayOffset 10\n",
    "PrintMotd no\n",
    "PrintLastLog yes\n",
    "TCPKeepAlive yes\n",
    "\n",
    "# Allow users\n",
    "AllowUsers admin root developer\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== SSH CONFIGURATION SECURITY ANALYSIS ===\")\n",
    "ssh_response = inference(make_config_prompt(ssh_config, \"SSH\"))\n",
    "display(Markdown(ssh_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: AWS IAM Policy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_policy = \"\"\"\n",
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Action\": \"*\",\n",
    "      \"Resource\": \"*\"\n",
    "    },\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Action\": [\n",
    "        \"s3:GetObject\",\n",
    "        \"s3:PutObject\"\n",
    "      ],\n",
    "      \"Resource\": \"arn:aws:s3:::my-bucket/*\",\n",
    "      \"Condition\": {\n",
    "        \"IpAddress\": {\n",
    "          \"aws:SourceIp\": \"0.0.0.0/0\"\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Action\": \"iam:*\",\n",
    "      \"Resource\": \"*\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== AWS IAM POLICY SECURITY ANALYSIS ===\")\n",
    "iam_response = inference(make_config_prompt(iam_policy, \"AWS IAM Policy\"))\n",
    "display(Markdown(iam_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Configuration Analysis\n",
    "\n",
    "Let's create a comprehensive analysis function that examines configurations from multiple security perspectives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_config_analysis(config_text, config_type):\n",
    "    \"\"\"Perform multi-perspective security analysis of configuration\"\"\"\n",
    "    \n",
    "    analyses = {\n",
    "        \"Attack Surface Analysis\": {\n",
    "            \"prompt\": f\"Analyze this {config_type} configuration focusing on attack surface exposure. Identify open ports, public access points, and potential entry vectors for attackers:\\n\\n{config_text}\",\n",
    "        },\n",
    "        \"Privilege Escalation Risks\": {\n",
    "            \"prompt\": f\"Examine this {config_type} configuration for privilege escalation risks. Look for overprivileged accounts, weak authentication, and paths to elevated access:\\n\\n{config_text}\",\n",
    "        },\n",
    "        \"Data Exposure Assessment\": {\n",
    "            \"prompt\": f\"Evaluate this {config_type} configuration for data exposure risks. Identify logging issues, unencrypted data paths, and information disclosure vulnerabilities:\\n\\n{config_text}\",\n",
    "        },\n",
    "        \"Compliance Gap Analysis\": {\n",
    "            \"prompt\": f\"Review this {config_type} configuration against security best practices and compliance standards (CIS, NIST, etc.). Identify gaps and non-compliant settings:\\n\\n{config_text}\",\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for analysis_type, config in analyses.items():\n",
    "        print(f\"\\n=== {analysis_type.upper()} ===\")\n",
    "        response = inference(config[\"prompt\"])\n",
    "        results[analysis_type] = response\n",
    "        display(Markdown(f\"### {analysis_type}\\n{response}\"))\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Comprehensive configuration analysis function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive analysis on the Terraform configuration\n",
    "print(\"=== COMPREHENSIVE TERRAFORM ANALYSIS ===\")\n",
    "terraform_comprehensive = comprehensive_config_analysis(terraform_config, \"Terraform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Remediation Generator\n",
    "\n",
    "Generate specific fixes for identified issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_remediation_plan(config_text, config_type):\n",
    "    \"\"\"Generate a detailed remediation plan with code examples\"\"\"\n",
    "    \n",
    "    remediation_prompt = f\"\"\"Analyze this {config_type} configuration and create a detailed remediation plan.\n",
    "    \n",
    "    For each security issue you identify:\n",
    "    1. Describe the specific problem\n",
    "    2. Explain the security risk\n",
    "    3. Provide the exact corrected configuration\n",
    "    4. Explain why the fix improves security\n",
    "    5. Note any trade-offs or considerations\n",
    "    \n",
    "    Format as a step-by-step remediation guide with before/after code examples.\n",
    "    \n",
    "    Configuration to analyze:\n",
    "    {config_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    return inference(remediation_prompt)\n",
    "\n",
    "print(\"=== TERRAFORM REMEDIATION PLAN ===\")\n",
    "remediation_plan = generate_remediation_plan(terraform_config, \"Terraform\")\n",
    "display(Markdown(remediation_plan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Configuration Analysis\n",
    "\n",
    "Analyze your own configuration files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own configuration here for analysis\n",
    "custom_config = \"\"\"\n",
    "# Paste your configuration file content here\n",
    "# Examples: Dockerfile, Kubernetes YAML, nginx.conf, etc.\n",
    "\"\"\"\n",
    "\n",
    "custom_config_type = \"Custom\"  # Specify the type: Dockerfile, Kubernetes, nginx, etc.\n",
    "\n",
    "if custom_config.strip() and not custom_config.startswith(\"# Paste your\"):\n",
    "    print(f\"=== CUSTOM {custom_config_type.upper()} CONFIGURATION ANALYSIS ===\")\n",
    "    custom_response = inference(make_config_prompt(custom_config, custom_config_type))\n",
    "    display(Markdown(custom_response))\n",
    "    \n",
    "    print(f\"\\n=== {custom_config_type.upper()} REMEDIATION PLAN ===\")\n",
    "    custom_remediation = generate_remediation_plan(custom_config, custom_config_type)\n",
    "    display(Markdown(custom_remediation))\n",
    "else:\n",
    "    print(\"Add your configuration content in the cell above to analyze it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Security Configuration Scorecard\n",
    "\n",
    "Generate a security score and summary for your configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_security_scorecard(config_text, config_type):\n",
    "    \"\"\"Generate a security scorecard with numerical scores\"\"\"\n",
    "    \n",
    "    scorecard_prompt = f\"\"\"Analyze this {config_type} configuration and provide a security scorecard.\n",
    "    \n",
    "    Provide scores (1-10, where 10 is most secure) for:\n",
    "    1. Access Control (authentication, authorization)\n",
    "    2. Network Security (firewall rules, port exposure)\n",
    "    3. Data Protection (encryption, data handling)\n",
    "    4. Logging & Monitoring (audit trails, visibility)\n",
    "    5. Configuration Hardening (secure defaults, unnecessary features)\n",
    "    \n",
    "    Also provide:\n",
    "    - Overall Security Score (average)\n",
    "    - Top 3 Critical Issues\n",
    "    - Top 3 Quick Wins (easy fixes with high impact)\n",
    "    - Compliance Status (CIS, NIST alignment)\n",
    "    \n",
    "    Configuration:\n",
    "    {config_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    return inference(scorecard_prompt)\n",
    "\n",
    "print(\"=== TERRAFORM SECURITY SCORECARD ===\")\n",
    "scorecard = generate_security_scorecard(terraform_config, \"Terraform\")\n",
    "display(Markdown(scorecard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Assessment Summary\n",
    "\n",
    "This notebook demonstrates comprehensive security analysis of configuration files using the Cisco Foundation Security model:\n",
    "\n",
    "- **Multi-layered Analysis**: Attack surface, privilege escalation, data exposure, and compliance perspectives\n",
    "- **Specific Remediation**: Detailed fixes with before/after code examples\n",
    "- **Security Scoring**: Quantitative assessment across multiple security domains\n",
    "- **Multiple Config Types**: Terraform, SSH, IAM policies, and custom configurations\n",
    "\n",
    "The model excels at contextual understanding of how configuration settings interact and impact overall security posture, going beyond simple rule-based checking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",\n",
   "language": "python",\n",
   "name": "python3"\n",
  },\n",
  "language_info": {\n",
   "codemirror_mode": {\n",
    "name": "ipython",\n",
    "version": 3\n",
   },\n",
   "file_extension": ".py",\n",
   "mimetype": "text/x-python",\n",
   "name": "python",\n",
   "nbconvert_exporter": "python",\n",
   "pygments_lexer": "ipython3",\n",
   "version": "3.10.12"\n",
  }\n },\n "nbformat": 4,\n "nbformat_minor": 4\n}
