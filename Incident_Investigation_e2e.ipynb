{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AI5ozM2h2Nva"
   },
   "source": [
    "# Incident Investigation Automation\n",
    "\n",
    "Automate key phases of incident investigation using a coordinated set of LLM-driven agents. These agents handle tasks such as triaging, summarizing, planning next steps, and generating recommendations, ultimately producing detailed investigation reports for SOC teams with minimal manual effort.\n",
    "\n",
    "## Model used for this use case\n",
    "This use case involves series of complex tasks so the Reasoning Model capabilities are leveraged via SageMaker endpoint for comprehensive incident analysis.\n",
    "\n",
    "**Note**: Update the configuration variables below to match your deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Update these variables to match your SageMaker deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE THESE VARIABLES TO MATCH YOUR DEPLOYMENT\n",
    "endpoint_name = 'foundation-sec-8b-endpoint'  # Your SageMaker endpoint name\n",
    "aws_region = 'us-east-1'  # Your AWS region\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"Endpoint: {endpoint_name}\")\n",
    "print(f\"Region: {aws_region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The setup uses SageMaker endpoint instead of loading the model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import re\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Initialize SageMaker runtime client\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime', region_name=aws_region)\n",
    "\n",
    "print(f\"Connected to SageMaker endpoint: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation arguments optimized for reasoning and analysis\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"temperature\": None,  # Deterministic for consistent analysis\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"do_sample\": False,\n",
    "    \"use_cache\": True,\n",
    "}\n",
    "\n",
    "print(\"Generation configuration:\")\n",
    "for key, value in generation_args.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(prompt):\n",
    "    \"\"\"Inference function using SageMaker endpoint for incident analysis\"\"\"\n",
    "    \n",
    "    # Format the prompt for reasoning-style analysis\n",
    "    formatted_prompt = f\"User: {prompt}\\n\\nAssistant: Let me analyze this incident step by step.\"\n",
    "    \n",
    "    # Prepare payload for SageMaker endpoint\n",
    "    payload = {\n",
    "        \"inputs\": formatted_prompt,\n",
    "        \"parameters\": generation_args\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = sagemaker_runtime.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType='application/json',\n",
    "            Body=json.dumps(payload)\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response['Body'].read().decode())\n",
    "        \n",
    "        # Handle different TGI response formats\n",
    "        if isinstance(result, list) and len(result) > 0:\n",
    "            generated_text = result[0].get('generated_text', '')\n",
    "        elif isinstance(result, dict):\n",
    "            generated_text = result.get('generated_text', str(result))\n",
    "        else:\n",
    "            generated_text = str(result)\n",
    "        \n",
    "        # Clean up the response (remove the original prompt if it's included)\n",
    "        if generated_text.startswith(formatted_prompt):\n",
    "            response_text = generated_text[len(formatted_prompt):].strip()\n",
    "        else:\n",
    "            response_text = generated_text.strip()\n",
    "            \n",
    "        # Remove any trailing special tokens\n",
    "        response_text = re.sub(r'<\\|.*?\\|>$', '', response_text).strip()\n",
    "        \n",
    "        return response_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking endpoint: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test the inference function\n",
    "test_response = inference(\"Test incident analysis capability\")\n",
    "print(\"Test Response:\")\n",
    "print(test_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": \"-2XV1flWD-qM\""
   },
   "source": [
    "## Step 1: Summarize Incident\n",
    "\n",
    "Analyze incident metadata and alert logs to provide a clear summary of what occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt_summarize_incident(metadata: dict, alert_logs: str) -> str:\n",
    "    return (\n",
    "        \"You are a senior SOC analyst assisting with incident triage. \"\n",
    "        \"Your task is to read the incident metadata and alert logs, and provide a clear summary of what occurred.\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"- Highlight the sequence of events (inferred from timestamps).\\n\"\n",
    "        \"- Think deeply about cause and effect and how artifacts relate to one another.\\n\"\n",
    "        \"- Mention key attack techniques used (if inferable from logs).\\n\"\n",
    "        \"- Describe how the attack began and progressed.\\n\"\n",
    "        \"- Use clear and concise language appropriate for L1/L2 analysts.\\n\\n\"\n",
    "        f\"Incident Metadata:\\n{metadata}\\n\\n\"\n",
    "        f\"Alert Logs:\\n{alert_logs}\\n\\n\"\n",
    "        \"Summarize what happened in this incident in a few sentences\"\n",
    "    )\n",
    "\n",
    "print(\"Incident summarization function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample incident data for analysis\n",
    "incident_meta = {\n",
    "    \"incident_id\": \"INC-1024\",\n",
    "    \"type\": \"Unauthorized Access\",\n",
    "    \"severity\": \"High\",\n",
    "    \"timestamp\": \"2025-04-09T10:30:00Z\"\n",
    "}\n",
    "\n",
    "raw_logs = \"\"\"2025-04-09 10:00:23 - Alert: 5 failed login attempts for user 'alice' on host 'WS123'\n",
    "2025-04-09 10:05:10 - Alert: Suspicious PowerShell execution on 'WS123' by 'alice' (malicious script blocked)\n",
    "2025-04-09 10:10:45 - Alert: Process dumping LSASS memory on 'WS123' (possible credential theft)\n",
    "2025-04-09 10:15:00 - Alert: Successful login of 'alice' to server 'DC1' from host 'WS123'\"\"\"\n",
    "\n",
    "print(\"Sample incident data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== INCIDENT SUMMARY GENERATION ===\")\n",
    "generated_summary = inference(make_prompt_summarize_incident(incident_meta, raw_logs))\n",
    "display(Markdown(generated_summary))\n",
    "print(\"\\nSummary completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": \"HwDT1ord4Vkl\""
   },
   "source": [
    "## Step 2: Identify Impacted Assets, Users, and MITRE Tactics\n",
    "\n",
    "Extract structured information about what was affected and which attack techniques were observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_incident_entities(metadata, logs):\n",
    "    \"\"\"Extract structured information from incident data\"\"\"\n",
    "    \n",
    "    prompt = (\n",
    "        \"You are a cybersecurity expert specializing in threat analysis and incident response. \"\n",
    "        \"Analyze the following incident logs and metadata, then:\\n\"\n",
    "        \"- List impacted host systems and IPs\\n\"\n",
    "        \"- List impacted user accounts\\n\"\n",
    "        \"- Identify MITRE ATT&CK tactics and techniques observed (with names or IDs)\\n\\n\"\n",
    "        f\"Metadata: {metadata}\\n\"\n",
    "        f\"Logs:\\n{logs}\\n\\n\"\n",
    "        \"Provide the result as a JSON object with no comments where:\\n\"\n",
    "        \"- keys are 'impacted_hosts', 'impacted_users', 'tactics', all of which are lists\\n\"\n",
    "        \"- each tactic in 'tactics' should have 'name' and 'techniques' keys\\n\"\n",
    "        \"- each technique in 'techniques' should have 'id' and 'name' keys\\n\"\n",
    "        \"Only output valid JSON\"\n",
    "    )\n",
    "    \n",
    "    return inference(prompt)\n",
    "\n",
    "print(\"=== EXTRACTING INCIDENT ENTITIES ===\")\n",
    "generated_entities_raw = extract_incident_entities(incident_meta, raw_logs)\n",
    "print(\"Raw response:\")\n",
    "print(generated_entities_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and clean the JSON response\n",
    "def parse_json_response(response_text):\n",
    "    \"\"\"Extract and parse JSON from model response\"\"\"\n",
    "    \n",
    "    # Try to find JSON in the response\n",
    "    json_match = re.search(r'\\{[\\s\\S]*\\}', response_text)\n",
    "    if json_match:\n",
    "        try:\n",
    "            return json.loads(json_match.group(0))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"No JSON object found in response.\")\n",
    "        return None\n",
    "\n",
    "generated_entities = parse_json_response(generated_entities_raw)\n",
    "\n",
    "if generated_entities:\n",
    "    print(\"\\n=== PARSED INCIDENT ENTITIES ===\")\n",
    "    print(json.dumps(generated_entities, indent=2))\n",
    "else:\n",
    "    print(\"Failed to parse entities. Using fallback data.\")\n",
    "    # Fallback data in case parsing fails\n",
    "    generated_entities = {\n",
    "        \"impacted_hosts\": [\"WS123\", \"DC1\"],\n",
    "        \"impacted_users\": [\"alice\"],\n",
    "        \"tactics\": [\n",
    "            {\n",
    "                \"name\": \"Initial Access\",\n",
    "                \"techniques\": [{\"id\": \"T1110\", \"name\": \"Brute Force\"}]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Credential Access\", \n",
    "                \"techniques\": [{\"id\": \"T1003\", \"name\": \"OS Credential Dumping\"}]\n",
    "            }\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": \"zRjIPlV9_FzR\""
   },
   "source": [
    "## Step 3: Recommend Remediation Steps and Next Investigative Actions\n",
    "\n",
    "Generate actionable recommendations based on the incident analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt_for_recommend_actions(summary, entities) -> str:\n",
    "    \"\"\"Generate remediation and next steps recommendations\"\"\"\n",
    "    \n",
    "    impacted_hosts = \", \".join(entities.get(\"impacted_hosts\", []))\n",
    "    impacted_users = \", \".join(entities.get(\"impacted_users\", []))\n",
    "    \n",
    "    tactics_list = []\n",
    "    for tactic in entities.get(\"tactics\", []):\n",
    "        for technique in tactic.get(\"techniques\", []):\n",
    "            tactics_list.append(f\"{tactic['name']}: {technique['name']} ({technique['id']})\")\n",
    "\n",
    "    context = (\n",
    "        f\"Incident Summary: {summary}\\n\"\n",
    "        f\"Impacted Hosts: {impacted_hosts}\\n\"\n",
    "        f\"Impacted Users: {impacted_users}\\n\"\n",
    "        f\"Observed Tactics: {tactics_list}\\n\\n\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        \"You are a SOC incident response assistant. Based on the incident details, \"\n",
    "        \"provide immediate remediation steps and next investigative actions.\\n\\n\"\n",
    "        \"Respond in the following JSON format:\\n\"\n",
    "        '{\\n  \"remediation_steps\": [\"step1\", \"step2\", ...],\\n  \"next_steps\": [\"action1\", \"action2\", ...]\\n}\\n\\n'\n",
    "        + context +\n",
    "        \"Focus on containment, eradication, and recovery actions.\"\n",
    "    )\n",
    "\n",
    "print(\"=== GENERATING REMEDIATION RECOMMENDATIONS ===\")\n",
    "remediation_response = inference(make_prompt_for_recommend_actions(generated_summary, generated_entities))\n",
    "print(\"Raw remediation response:\")\n",
    "print(remediation_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse remediation recommendations\n",
    "generated_recommend_actions = parse_json_response(remediation_response)\n",
    "\n",
    "if generated_recommend_actions:\n",
    "    print(\"\\n=== PARSED REMEDIATION ACTIONS ===\")\n",
    "    print(json.dumps(generated_recommend_actions, indent=2))\n",
    "else:\n",
    "    print(\"Failed to parse remediation actions. Using fallback data.\")\n",
    "    # Fallback data\n",
    "    generated_recommend_actions = {\n",
    "        \"remediation_steps\": [\n",
    "            \"Isolate affected systems WS123 and DC1 from network\",\n",
    "            \"Reset credentials for user 'alice' and force password change\",\n",
    "            \"Scan for additional compromised accounts\",\n",
    "            \"Review and strengthen authentication policies\"\n",
    "        ],\n",
    "        \"next_steps\": [\n",
    "            \"Conduct forensic analysis on WS123\",\n",
    "            \"Monitor for lateral movement indicators\",\n",
    "            \"Review security awareness training\",\n",
    "            \"Update incident response procedures\"\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": \"9VIchk88Ckbv\""
   },
   "source": [
    "## Step 4: Produce a Structured Incident Investigation Report\n",
    "\n",
    "Compile all analysis into a comprehensive incident report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_report_prompt(metadata: dict, summary: str, entities: dict, actions: dict) -> str:\n",
    "    \"\"\"Generate a comprehensive incident investigation report\"\"\"\n",
    "    \n",
    "    hosts = \", \".join(entities.get(\"impacted_hosts\", []))\n",
    "    users = \", \".join(entities.get(\"impacted_users\", []))\n",
    "    \n",
    "    tactics = []\n",
    "    for tactic in entities.get(\"tactics\", []):\n",
    "        for technique in tactic.get(\"techniques\", []):\n",
    "            tactics.append(f\"{tactic['name']}: {technique['name']} ({technique['id']})\")\n",
    "    \n",
    "    remediation_list = \"- \" + \"\\n- \".join(\n",
    "        str(step) for step in actions.get(\"remediation_steps\", [])\n",
    "    )\n",
    "    \n",
    "    next_steps_list = \"- \" + \"\\n- \".join(\n",
    "        str(step) for step in actions.get(\"next_steps\", [])\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        \"You are a SOC analyst assistant tasked with writing the final incident report. \"\n",
    "        \"Use the information below to create a comprehensive, professional incident report.\\n\\n\"\n",
    "        f\"Incident Metadata: {metadata}\\n\"\n",
    "        f\"Incident Summary: {summary}\\n\"\n",
    "        f\"Impacted Hosts: {hosts}\\n\"\n",
    "        f\"Impacted Users: {users}\\n\"\n",
    "        f\"Observed Tactics/Techniques: {tactics}\\n\"\n",
    "        f\"Remediation Steps Taken:\\n{remediation_list}\\n\"\n",
    "        f\"Next Investigation Steps:\\n{next_steps_list}\\n\\n\"\n",
    "        \"Format the incident report with these sections:\\n\"\n",
    "        \"# Incident Report: [Title]\\n\"\n",
    "        \"## Executive Summary\\n\"\n",
    "        \"## Incident Details\\n\"\n",
    "        \"### Timeline of Events\\n\"\n",
    "        \"### Impacted Assets and Users\\n\"\n",
    "        \"### Attack Techniques (MITRE ATT&CK)\\n\"\n",
    "        \"## Response Actions\\n\"\n",
    "        \"### Immediate Containment\\n\"\n",
    "        \"### Remediation Steps\\n\"\n",
    "        \"## Next Steps and Recommendations\\n\"\n",
    "        \"## Lessons Learned\\n\\n\"\n",
    "        \"Return the report in Markdown format with professional language suitable for management review.\"\n",
    "    )\n",
    "\n",
    "print(\"=== GENERATING COMPREHENSIVE INCIDENT REPORT ===\")\n",
    "report = inference(make_report_prompt(incident_meta, generated_summary, generated_entities, generated_recommend_actions))\n",
    "display(Markdown(report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Multi-Incident Analysis\n",
    "\n",
    "Analyze multiple related incidents to identify patterns and campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional incident data for pattern analysis\n",
    "incident_2 = {\n",
    "    \"metadata\": {\n",
    "        \"incident_id\": \"INC-1025\",\n",
    "        \"type\": \"Data Exfiltration\",\n",
    "        \"severity\": \"Critical\",\n",
    "        \"timestamp\": \"2025-04-10T14:15:00Z\"\n",
    "    },\n",
    "    \"logs\": \"\"\"2025-04-10 14:00:12 - Alert: Large data transfer from 'alice' account to external IP 198.51.100.50\n",
    "2025-04-10 14:05:30 - Alert: Suspicious zip file creation on DC1 containing sensitive files\n",
    "2025-04-10 14:10:15 - Alert: Encrypted communication detected to known C2 server\n",
    "2025-04-10 14:15:45 - Alert: Data exfiltration attempt blocked by DLP policy\"\"\"\n",
    "}\n",
    "\n",
    "def analyze_incident_patterns(incidents):\n",
    "    \"\"\"Analyze multiple incidents for patterns and relationships\"\"\"\n",
    "    \n",
    "    incidents_text = \"\\n\\n\".join([\n",
    "        f\"Incident {i+1}:\\nMetadata: {inc.get('metadata', {})}\\nLogs: {inc.get('logs', '')}\" \n",
    "        for i, inc in enumerate(incidents)\n",
    "    ])\n",
    "    \n",
    "    prompt = (\n",
    "        \"You are a threat intelligence analyst examining multiple related incidents. \"\n",
    "        \"Analyze the incidents below for:\\n\"\n",
    "        \"- Common indicators (IPs, users, techniques)\\n\"\n",
    "        \"- Attack progression patterns\\n\"\n",
    "        \"- Evidence of coordinated campaign\\n\"\n",
    "        \"- Attribution indicators\\n\\n\"\n",
    "        f\"Incidents to analyze:\\n{incidents_text}\\n\\n\"\n",
    "        \"Provide analysis in clear sections with specific evidence.\"\n",
    "    )\n",
    "    \n",
    "    return inference(prompt)\n",
    "\n",
    "print(\"=== MULTI-INCIDENT PATTERN ANALYSIS ===\")\n",
    "pattern_analysis = analyze_incident_patterns([{\n",
    "    \"metadata\": incident_meta,\n",
    "    \"logs\": raw_logs\n",
    "}, incident_2])\n",
    "\n",
    "display(Markdown(pattern_analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Incident Analysis\n",
    "\n",
    "Analyze your own incident data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your custom incident data here\n",
    "custom_incident_meta = {\n",
    "    \"incident_id\": \"YOUR-INCIDENT-ID\",\n",
    "    \"type\": \"Incident Type\",\n",
    "    \"severity\": \"Severity Level\",\n",
    "    \"timestamp\": \"YYYY-MM-DDTHH:MM:SSZ\"\n",
    "}\n",
    "\n",
    "custom_logs = \"\"\"\n",
    "# Paste your incident logs here\n",
    "# Format: timestamp - Alert: description\n",
    "\"\"\"\n",
    "\n",
    "if custom_logs.strip() and not custom_logs.startswith(\"# Paste your\"):\n",
    "    print(\"=== ANALYZING CUSTOM INCIDENT ===\")\n",
    "    \n",
    "    # Run full analysis pipeline\n",
    "    custom_summary = inference(make_prompt_summarize_incident(custom_incident_meta, custom_logs))\n",
    "    print(\"\\n--- Custom Incident Summary ---\")\n",
    "    display(Markdown(custom_summary))\n",
    "    \n",
    "    custom_entities_raw = extract_incident_entities(custom_incident_meta, custom_logs)\n",
    "    custom_entities = parse_json_response(custom_entities_raw)\n",
    "    \n",
    "    if custom_entities:\n",
    "        custom_actions_raw = inference(make_prompt_for_recommend_actions(custom_summary, custom_entities))\n",
    "        custom_actions = parse_json_response(custom_actions_raw)\n",
    "        \n",
    "        if custom_actions:\n",
    "            print(\"\\n--- Custom Incident Report ---\")\n",
    "            custom_report = inference(make_report_prompt(custom_incident_meta, custom_summary, custom_entities, custom_actions))\n",
    "            display(Markdown(custom_report))\n",
    "        else:\n",
    "            print(\"Failed to generate remediation actions for custom incident\")\n",
    "    else:\n",
    "        print(\"Failed to extract entities from custom incident\")\n",
    "else:\n",
    "    print(\"Add your incident data in the cells above to analyze it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incident Investigation Automation Summary\n",
    "\n",
    "This notebook demonstrates a complete incident investigation automation pipeline:\n",
    "\n",
    "1. **Incident Summarization** - Automated analysis of logs and metadata\n",
    "2. **Entity Extraction** - Identification of affected assets, users, and attack techniques\n",
    "3. **Remediation Planning** - Generation of containment and recovery actions\n",
    "4. **Report Generation** - Comprehensive documentation for stakeholders\n",
    "5. **Pattern Analysis** - Multi-incident correlation and threat intelligence\n",
    "\n",
    "The automation significantly reduces manual effort while ensuring consistent, thorough analysis of security incidents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",\n",
   "language": "python",\n",
   "name": "python3"
  },\n",
  "language_info": {\n",
   "codemirror_mode": {\n",
    "name": "ipython",\n",
    "version": 3\n",
   },\n",
   "file_extension": ".py",\n",
   "mimetype": "text/x-python",\n",
   "name": "python",\n",
   "nbconvert_exporter": "python",\n",
   "pygments_lexer": "ipython3",\n",
   "version": "3.10.12"\n",
  }\n },\n "nbformat": 4,\n "nbformat_minor": 4\n}
