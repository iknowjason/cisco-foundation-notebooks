{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75c09f8",
   "metadata": {
    "id": "b75c09f8"
   },
   "source": [
    "## Getting Started\n",
    "This notebook demonstrates how to use the Foundation-Sec-8B model for cybersecurity text classification. Whether you're a security analyst, researcher, or just getting started with AI, this guide will help you automatically categorize cybersecurity-related text into relevant categories.\n",
    "\n",
    "---\n",
    "\n",
    "### What This Notebook Does\n",
    "Foundation-Sec-8B is a specialized language model trained specifically for cybersecurity tasks. This notebook shows you how to:\n",
    "- Automatically classify cybersecurity text into categories like:\n",
    "    - Malware (viruses, ransomware, trojans)\n",
    "    - Phishing (fake emails, social engineering)\n",
    "    - Vulnerabilities (security flaws, CVEs)\n",
    "    - Incident Response (breach containment, forensics)\n",
    "    - Threat Intelligence (APT groups, attack patterns)\n",
    "    - Compliance (GDPR, regulations, audits)\n",
    "    - Data Breaches (leaked information, exposures)\n",
    "\n",
    "- Use advanced perplexity-based classification for high accuracy\n",
    "- Provide confidence scores for each prediction\n",
    "- Process single texts or batches of documents\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use This Approach (and When Not To!)\n",
    "\n",
    "This notebook uses perplexity-based classification, which evaluates how well each category \"explains\" the input text by computing its perplexity under prompts conditioned on each class label.\n",
    "\n",
    "#### âœ… Advantages â€“ When to Use:\n",
    "\n",
    "* Instruction fidelity is guaranteed: Unlike completion-style classification, the model is never asked to generate an open-ended label, so it cannot hallucinate or disobey label constraints.\n",
    "\n",
    "* Label control: All predictions are restricted to a fixed set of known categories, making it suitable for high-stakes or rule-based classification environments.\n",
    "\n",
    "* No need for task-specific fine-tuning: You can use this out-of-the-box with Foundation-Sec-8B without collecting or labeling new data.\n",
    "\n",
    "* High interpretability: Confidence scores are derived from actual model perplexity, making decision boundaries easier to inspect.\n",
    "\n",
    "#### âš ï¸ Limitations â€“ When Not To Use:\n",
    "\n",
    "* **Scalability**: This approach runs a separate forward pass per class, so latency and cost scale linearly with the number of categories. For small to moderate class counts (\\~10 or fewer), this is acceptable. For hundreds or thousands of classes, this becomes infeasible.\n",
    "\n",
    "* **When high-throughput is critical**: If you're deploying real-time systems or large-scale pipelines, this may not be performant enough.\n",
    "\n",
    "#### ðŸ‘‰ Alternatives:\n",
    "\n",
    "If you're working with many categories or need real-time performance, consider using the finetuned classification model instead. See the [Finetuning Classification Notebook](https://github.com/RobustIntelligence/foundation-ai-cookbook/blob/main/2_examples/Classification_cybersecurity_descriptions.ipynb) for instructions on how to train and deploy a task-specific classifier.\n",
    "\n",
    "---\n",
    "\n",
    "### What is Perplexity Classification?\n",
    "Perplexity measures how \"surprised\" a language model is by a piece of text. Lower perplexity means the model finds the text more predictable given a certain context. We use this to determine which category best fits your cybersecurity text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f10e04",
   "metadata": {
    "id": "03f10e04",
    "papermill": {
     "duration": 0.002622,
     "end_time": "2025-06-18T19:03:12.429682",
     "exception": false,
     "start_time": "2025-06-18T19:03:12.427060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installing Libraries\n",
    "\n",
    "### Model Available here([Link](https://huggingface.co/fdtn-ai/Foundation-Sec-8B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2fe1fc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-18T19:03:12.434108Z",
     "iopub.status.busy": "2025-06-18T19:03:12.433897Z",
     "iopub.status.idle": "2025-06-18T19:05:24.150196Z",
     "shell.execute_reply": "2025-06-18T19:05:24.149446Z"
    },
    "id": "4b2fe1fc",
    "outputId": "a40f2b39-45f0-4396-df40-461fa3a0fd9c",
    "papermill": {
     "duration": 131.72078,
     "end_time": "2025-06-18T19:05:24.152429",
     "exception": false,
     "start_time": "2025-06-18T19:03:12.431649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d705759e",
   "metadata": {
    "id": "d705759e",
    "papermill": {
     "duration": 0.017963,
     "end_time": "2025-06-18T19:05:24.189218",
     "exception": false,
     "start_time": "2025-06-18T19:05:24.171255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6e9d16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T19:05:24.224384Z",
     "iopub.status.busy": "2025-06-18T19:05:24.224114Z",
     "iopub.status.idle": "2025-06-18T19:05:30.867467Z",
     "shell.execute_reply": "2025-06-18T19:05:30.866680Z"
    },
    "id": "ca6e9d16",
    "papermill": {
     "duration": 6.662447,
     "end_time": "2025-06-18T19:05:30.868822",
     "exception": false,
     "start_time": "2025-06-18T19:05:24.206375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc2a5c",
   "metadata": {
    "id": "55cc2a5c",
    "papermill": {
     "duration": 0.01636,
     "end_time": "2025-06-18T19:05:30.902256",
     "exception": false,
     "start_time": "2025-06-18T19:05:30.885896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## NTP Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oszcpIXqSMTH",
   "metadata": {
    "id": "oszcpIXqSMTH"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ClassificationResult:\n",
    "    \"\"\"\n",
    "    Stores the results of text classification\n",
    "\n",
    "    Attributes:\n",
    "        predicted_label: The most likely category (e.g., \"malware\", \"phishing\")\n",
    "        confidence_score: How confident the model is (0-1, higher = more confident)\n",
    "        perplexity_scores: Technical scores for each category\n",
    "        raw_probabilities: Probability distribution across all categories\n",
    "    \"\"\"\n",
    "    predicted_label: str\n",
    "    confidence_score: float\n",
    "    perplexity_scores: Dict[str, float]\n",
    "    raw_probabilities: Dict[str, float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa902cc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T19:05:30.936240Z",
     "iopub.status.busy": "2025-06-18T19:05:30.935874Z",
     "iopub.status.idle": "2025-06-18T19:05:30.951374Z",
     "shell.execute_reply": "2025-06-18T19:05:30.950842Z"
    },
    "id": "aa902cc4",
    "papermill": {
     "duration": 0.033744,
     "end_time": "2025-06-18T19:05:30.952441",
     "exception": false,
     "start_time": "2025-06-18T19:05:30.918697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PerplexityClassifier:\n",
    "    \"\"\"\n",
    "    A cybersecurity text classifier using the Foundation-Sec-8B model\n",
    "\n",
    "    This class handles:\n",
    "    - Loading the specialized cybersecurity model\n",
    "    - Processing text through perplexity analysis\n",
    "    - Returning classification results with confidence scores\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"fdtn-ai/Foundation-Sec-8B\",\n",
    "                 labels: List[str] = None, device: str = \"auto\",\n",
    "                 run_quantized: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the classifier\n",
    "\n",
    "        Parameters:\n",
    "            model_name: The AI model to use (default: Foundation-Sec-8B)\n",
    "            labels: List of categories to classify into\n",
    "            device: Where to run the model (\"auto\", \"cpu\", or \"cuda\")\n",
    "            run_quantized: Use memory-efficient loading (recommended for large models)\n",
    "        \"\"\"\n",
    "        self.labels = labels or []\n",
    "        self.device = self._get_device(device)\n",
    "        self.run_quantized = run_quantized\n",
    "\n",
    "        # Load the tokenizer (converts text to numbers the model understands)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        # Load the model with appropriate settings\n",
    "        if run_quantized:\n",
    "            # Memory-efficient loading - uses 4-bit precision\n",
    "            quantization_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                bnb_4bit_use_double_quant=True,\n",
    "                bnb_4bit_quant_type=\"nf4\"\n",
    "            )\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                quantization_config=quantization_config,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "        else:\n",
    "            # Standard loading\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                torch_dtype=torch.bfloat16 if self.device.type == 'cuda' else torch.float32,\n",
    "                device_map=\"auto\" if self.device.type == 'cuda' else None\n",
    "            )\n",
    "            if self.device.type != 'cuda':\n",
    "                self.model = self.model.to(self.device)\n",
    "\n",
    "        # Set model to evaluation mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # Handle padding token for proper text processing\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def _get_device(self, device: str) -> torch.device:\n",
    "        \"\"\"Automatically detect the best device (GPU vs CPU)\"\"\"\n",
    "        if device == \"auto\":\n",
    "            return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        return torch.device(device)\n",
    "\n",
    "    def set_labels(self, labels: List[str]) -> None:\n",
    "        \"\"\"Set or update the classification categories\"\"\"\n",
    "        self.labels = labels\n",
    "\n",
    "    def _create_classification_prompt(self, text: str,\n",
    "                                    few_shot_examples: List[Tuple[str, str]] = None) -> str:\n",
    "        \"\"\"\n",
    "        Create a structured prompt for the model to understand the classification task\n",
    "\n",
    "        Parameters:\n",
    "            text: The cybersecurity text to classify\n",
    "            few_shot_examples: Optional examples to guide the model (format: [(text, label), ...])\n",
    "\n",
    "        Returns:\n",
    "            A formatted prompt that helps the model understand what to do\n",
    "        \"\"\"\n",
    "        prompt_parts = [\n",
    "            \"This is a cybersecurity text classification task.\",\n",
    "            f\"Available labels: {', '.join(self.labels)}\",\n",
    "            \"Choose the most appropriate label for the given text.\\n\"\n",
    "        ]\n",
    "\n",
    "        # Add examples if provided\n",
    "        if few_shot_examples:\n",
    "            prompt_parts.append(\"Examples:\")\n",
    "            for example_text, example_label in few_shot_examples:\n",
    "                prompt_parts.append(f'Text: \"\"\"{example_text}\"\"\"')\n",
    "                prompt_parts.append(f\"Chosen label: {example_label}\\n\")\n",
    "\n",
    "        # Add the text to classify\n",
    "        prompt_parts.extend([\n",
    "            f'Text: \"\"\"{text}\"\"\"',\n",
    "            \"Chosen label:\"\n",
    "        ])\n",
    "\n",
    "        return \"\\n\".join(prompt_parts)\n",
    "\n",
    "    def _calculate_batch_perplexities(self, prompt: str,\n",
    "                                    completions: List[str]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate perplexity scores for each possible label\n",
    "\n",
    "        Lower perplexity = model is more confident in that classification\n",
    "\n",
    "        Parameters:\n",
    "            prompt: The classification prompt\n",
    "            completions: List of possible labels to test\n",
    "\n",
    "        Returns:\n",
    "            Dictionary mapping each label to its perplexity score\n",
    "        \"\"\"\n",
    "        perplexities = {}\n",
    "\n",
    "        for completion in completions:\n",
    "            # Create full text: prompt + potential answer\n",
    "            full_text = prompt + \" \" + completion\n",
    "\n",
    "            # Convert text to model input\n",
    "            inputs = self.tokenizer(full_text, return_tensors=\"pt\",\n",
    "                                  truncation=True, max_length=2048)\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "            # Get length of just the prompt (not the completion)\n",
    "            prompt_inputs = self.tokenizer(prompt, return_tensors=\"pt\",\n",
    "                                         truncation=True, max_length=2048)\n",
    "            prompt_length = prompt_inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "            # Calculate perplexity\n",
    "            with torch.no_grad():  # Don't update model weights\n",
    "                outputs = self.model(**inputs)\n",
    "                logits = outputs.logits\n",
    "\n",
    "                # Focus only on the completion part\n",
    "                completion_logits = logits[0, prompt_length-1:-1]\n",
    "                completion_targets = inputs[\"input_ids\"][0, prompt_length:]\n",
    "\n",
    "                # Calculate cross-entropy loss (related to perplexity)\n",
    "                loss = F.cross_entropy(completion_logits, completion_targets, reduction='mean')\n",
    "\n",
    "                # Convert loss to perplexity\n",
    "                perplexities[completion] = torch.exp(loss).item()\n",
    "\n",
    "        return perplexities\n",
    "\n",
    "    def classify(self, text: str,\n",
    "                few_shot_examples: List[Tuple[str, str]] = None,\n",
    "                return_all_scores: bool = False) -> ClassificationResult:\n",
    "        \"\"\"\n",
    "        Classify a piece of cybersecurity text\n",
    "\n",
    "        Parameters:\n",
    "            text: The cybersecurity text to classify\n",
    "            few_shot_examples: Optional examples to improve accuracy\n",
    "            return_all_scores: Whether to return scores for all categories\n",
    "\n",
    "        Returns:\n",
    "            ClassificationResult with prediction and confidence scores\n",
    "        \"\"\"\n",
    "        if not self.labels:\n",
    "            raise ValueError(\"No labels set. Use set_labels() to define classification labels.\")\n",
    "\n",
    "        # Create the classification prompt\n",
    "        prompt = self._create_classification_prompt(text, few_shot_examples)\n",
    "\n",
    "        # Calculate perplexity for each possible label\n",
    "        perplexity_scores = self._calculate_batch_perplexities(prompt, self.labels)\n",
    "\n",
    "        # Convert perplexities to probabilities (lower perplexity = higher probability)\n",
    "        raw_probabilities = {\n",
    "            label: 1.0 / perp if perp != float('inf') else 0.0\n",
    "            for label, perp in perplexity_scores.items()\n",
    "        }\n",
    "\n",
    "        # Find the best (lowest perplexity) label\n",
    "        best_label = min(perplexity_scores.keys(), key=lambda x: perplexity_scores[x])\n",
    "\n",
    "        # Normalize probabilities to sum to 1\n",
    "        total_inverse_perplexity = sum(raw_probabilities.values())\n",
    "        normalized_probabilities = {\n",
    "            label: prob / total_inverse_perplexity if total_inverse_perplexity > 0 else 1.0/len(self.labels)\n",
    "            for label, prob in raw_probabilities.items()\n",
    "        }\n",
    "\n",
    "        # Calculate confidence as concentration of probability mass\n",
    "        confidence_score = sum(p**2 for p in normalized_probabilities.values())\n",
    "\n",
    "        return ClassificationResult(\n",
    "            predicted_label=best_label,\n",
    "            confidence_score=confidence_score,\n",
    "            perplexity_scores=perplexity_scores if return_all_scores else {best_label: perplexity_scores[best_label]},\n",
    "            raw_probabilities=normalized_probabilities if return_all_scores else {best_label: normalized_probabilities[best_label]}\n",
    "        )\n",
    "\n",
    "    def batch_classify(self, texts: List[str],\n",
    "                      few_shot_examples: List[Tuple[str, str]] = None) -> List[ClassificationResult]:\n",
    "        \"\"\"\n",
    "        Classify multiple texts at once\n",
    "\n",
    "        Parameters:\n",
    "            texts: List of cybersecurity texts to classify\n",
    "            few_shot_examples: Optional examples to improve accuracy\n",
    "\n",
    "        Returns:\n",
    "            List of ClassificationResult objects, one for each input text\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            result = self.classify(text, few_shot_examples)\n",
    "            results.append(result)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea01d35",
   "metadata": {
    "id": "8ea01d35",
    "papermill": {
     "duration": 0.016578,
     "end_time": "2025-06-18T19:05:30.985790",
     "exception": false,
     "start_time": "2025-06-18T19:05:30.969212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Real-World Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9bc454",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955,
     "referenced_widgets": [
      "4e9ba8d467ce46309288ccaef65fa045",
      "16e7cc0775b64ea5a7a887688b3f8996",
      "79500a10d0194b10a487159d5a4ae22d",
      "bcf09e06ee3c423fa88862a24b1a0e8e",
      "17f26aaf20e543eb9fb5bd9e5c9caec0",
      "971f7d51d8f6445294d4690d7a429688",
      "2dac6adaa821449cacdfc9d0826faef1",
      "8742061956c54d5d9b2bcae290000fe8",
      "6f54115cf17b45b686435975210a264f",
      "786a062ee4494a669e447148c9feab78",
      "4bb4469637d741728dd79f622907129f",
      "8c4b46f149154331ab95c43628efc52d",
      "f6f10b3c98cb4c5b9c056a5e928c1d05",
      "5d7713b0d3e444f48ddcc96fa2812043",
      "919668119ef448f3857458bfffdf24cd",
      "d1146d27245a4ce9a8b5daf61678a328",
      "30cdf2de5a14483490bf963270402eae",
      "1a3add775a3f44c3861e92ff2607271b",
      "fc2ba126eb924d94960efbcb06ca9575",
      "eaa3adf30058497eb95d9c6a770526f4",
      "18ecb72a1b2d4e769bf88e25be5cb180",
      "7a21b2f7b5a94cdbb48d6b2f3ac7909d",
      "c83673679f344157ad95e04df60b95df",
      "4c7ce7241b814652b396c95cf27fcd09",
      "6ad0ae609bb746fc9e8385903a887eab",
      "19d6017348684fd891d3d16acc3a0a55",
      "354ac6e6d39844e4b7ac0d3644528192",
      "3b52cac1b4314b87b55fee404ee30064",
      "6b3fd0f0fbc84541a57cf6b3b1b7a822",
      "ab870bde5c964b939bbe2b800d6a9a40",
      "2ad7437bfb3f4173b9230dbf185eb140",
      "46e589fb253d450e94f2dbcf763bb730",
      "ab56d0a3f7964c9b958d0f7623955255",
      "933ff68df6c04c4e9cf05b5ec742b3f5",
      "c85b74c0a262483fa7a157860f6a2fa1",
      "198e5b96f2fc4e4b8ccba8dd5f6cb410",
      "07f67014646f47c2baba7db3744245d2",
      "bf0a150952f3428184db1141f452eed0",
      "78b2027449da4ca39c960bd921a585bd",
      "1246f4df8cb24b7c95afda702116b017",
      "3563f0658bf746e1b63cb8d6453fa248",
      "632594a202a24cc687d11d9a8e9eef0d",
      "78c809d3cfef48f1a1bfd863db72f8b8",
      "c450783620c04d1cb5c33b950dea8497",
      "3043350482b6439088439c9a958dd3c7",
      "551aa7381df9451cbb506936ad50d8a9",
      "212550cdd2c849dfa15be854039e67a3",
      "04b53d91e6c648e5a4dd1d93e927a894",
      "1a7594d488fe4c679dfc2c65732474dc",
      "115370875f9a43518ed63f2062db67ee",
      "2dffc017a6b44c94862aea85df76b723",
      "688481230dfe4e0ea6c43b690011e3b9",
      "4aa28b79ebcc4d598a62b4a9e3e86cfb",
      "fa19a0e3d7654af98bf3439015da719a",
      "628e100acb864b3287ce527e341fa319",
      "804a2591a9a84e459ff9da9b02788647",
      "3360ce71b6534b7aa82b3bcbe9ca57a4",
      "f384e0ed94de4e82a14fa7b97365f4be",
      "2299f45c9f6848feb81db66afd92e256",
      "2d9ba35d01de4ec38ee70448b05e0837",
      "ad19885d257846c6921fa02da2e3d2e6",
      "8220f41ae0744e8b8d4c17a0807116ad",
      "4411265d966f41c4a135de2403c0a703",
      "6374d519e29144628bbc2ec317dd5b3e",
      "c4cb96ff490e4a20b5a8ca3cac0a00fb",
      "64f631f3ec074cf0bfc6d8967b49c916",
      "59d6e64f49784830a958a00dd192880a",
      "f285a163d2b74610863b8ec97dcae27e",
      "4cad4f0dcd334341a6f3faabe15ede98",
      "72f61ced5de94bd4967f70417018191b",
      "45a2058f687d40cebb3d9e92d0a4bcf1",
      "992854716c93401a947b0e2f661a3e97",
      "cabfd3cce01f4feabf8302af20df866e",
      "524c779019164fe3829f2c811bc51272",
      "5387a7a39f07434789bf5d07ee7aff87",
      "6a914c4c0bcf4b508a89a55343d6324d",
      "e36dcbde02a64b8fa8ca1fbf0ea2b0c7",
      "e1fa5f9895904f71946d186953fbda07",
      "7a875141409f40a69575a1c4fd26e433",
      "ad85ba6390bf4585ab714246c6f300ec",
      "ab7de53060154f06994116aa437ead46",
      "aea7b310b38f40ea8e9f3789b83a079b",
      "63d4f74e4766455bad4d9f94e03dde95",
      "f35a3ab3876349638e5021b4073b90ef",
      "f845ae8b71b647b68322ef7b52296aa8",
      "03d54dc70a61455f895e3daae04c0c4b",
      "8873244467b149d0ba25eabcb8077242",
      "6f0e93acb9e14eb59b727b5283d338a7",
      "54553266466841eb9de87b65c82a23f1",
      "cd6500d0461545aeae5a3fcbdc800ad7",
      "5bd570eaaf9943c3887f49d398471189",
      "e489a279252f40ec8ca1ad90ba325e63",
      "3aa7807a8a804df3a967feeb08b20131",
      "ed18224546804bcf9c2c85bdee8d1dc3",
      "7f5502fd79924689b737194c277cafe2",
      "0c31ed13841e4fbe990a0b6917b28911",
      "c5dc5da8413d4e75af05dc485908f5af",
      "19edf56568f24f8fb0978aa6c6d9f058",
      "94787284d9ac46c092fe9fe532840c83",
      "6e02df02d5344601a6b6782d26bc276a",
      "2bbeb04e2c8b41f1a829d903b87fb08a",
      "54279b20fc6141a8bf1c1a61436e8b86",
      "2741d7f896644c27b1deee1446c22db6",
      "f7474bc3a4374f92a915e5cae6809a30",
      "606da294bd194d04a83f11de345472ab",
      "c3c94e6c5e1545d0846c4899c4f92163",
      "9da7dead1cb14a9c9a5ce7f49ac7aba6",
      "827c8e73a0a54e7db903ad2706ca0612",
      "a5e9b7abcaa84c1786694e03b83488ff",
      "53bf76cadbf34e248b4d03317fe88de5",
      "22ccf2588ac54f27a2c4fb3024362ee7",
      "4db7f908054549e5a67bb9bedecd354e",
      "88abeb39bf184a0e9783c669432a8527",
      "093b2c069bc94402b4afbb88ce006af7",
      "2eee55517c9e422f86929dbf91c90bde",
      "ecd2525557384b3da814ecac2fa20020",
      "fdd92a1bb393445cade5ae75ad0e530b",
      "2460f730c7bc401b9bec9fbcc92d130f",
      "f6f3a1edb554458180b83e3ddcba3f99",
      "3ff95a28305e4d2fa6ee6da5d6688b5b",
      "4cad9f5ed3df47bdbd8c086f629fcaae",
      "3d87b8b959184b698757d2a2e79fe36a",
      "ee6c970ad4e147de9b6f8f61b141b2f1",
      "b0a6c929686143468770c6f3db25fe50",
      "36ae472a95b743849d2d5858ae4a1d0a",
      "ab6e99130c3a42deac0ab7edeff330eb",
      "b4bae5f85692478291588ffecd7981a8",
      "8e5c70924291438882c0d92eeb0deb81",
      "76ea56c18ba147f492ef2e5bea719df0",
      "db2ed291227e44bda3abfe0ed63e7838",
      "eeb37424278a471ca74913487e340d25",
      "b87a34f700324fdb8505428e70f8e5d8"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-06-18T19:05:31.020168Z",
     "iopub.status.busy": "2025-06-18T19:05:31.019737Z",
     "iopub.status.idle": "2025-06-18T19:07:57.798503Z",
     "shell.execute_reply": "2025-06-18T19:07:57.797655Z"
    },
    "id": "8a9bc454",
    "outputId": "b45d4cfc-95f7-4f53-f906-cb4861d5dffc",
    "papermill": {
     "duration": 146.797352,
     "end_time": "2025-06-18T19:07:57.799799",
     "exception": false,
     "start_time": "2025-06-18T19:05:31.002447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9ba8d467ce46309288ccaef65fa045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4b46f149154331ab95c43628efc52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83673679f344157ad95e04df60b95df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/630 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933ff68df6c04c4e9cf05b5ec742b3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/840 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3043350482b6439088439c9a958dd3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804a2591a9a84e459ff9da9b02788647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d6e64f49784830a958a00dd192880a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1fa5f9895904f71946d186953fbda07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54553266466841eb9de87b65c82a23f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e02df02d5344601a6b6782d26bc276a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ccf2588ac54f27a2c4fb3024362ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d87b8b959184b698757d2a2e79fe36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A critical buffer overflow vulnerability was discovered in t...\n",
      "Predicted: vulnerability\n",
      "Probability: 0.664\n",
      "Confidence: 0.486\n",
      "--------------------------------------------------\n",
      "Suspicious email attachment containing executable file detec...\n",
      "Predicted: phishing\n",
      "Probability: 0.375\n",
      "Confidence: 0.260\n",
      "--------------------------------------------------\n",
      "GDPR compliance audit revealed inadequate data processing co...\n",
      "Predicted: compliance\n",
      "Probability: 0.742\n",
      "Confidence: 0.578\n",
      "--------------------------------------------------\n",
      "Containment procedures activated following detection of late...\n",
      "Predicted: incident_response\n",
      "Probability: 0.811\n",
      "Confidence: 0.677\n",
      "--------------------------------------------------\n",
      "APT29 group observed using new PowerShell-based persistence ...\n",
      "Predicted: threat_intelligence\n",
      "Probability: 0.721\n",
      "Confidence: 0.568\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def demo_security_classification():\n",
    "    classifier = PerplexityClassifier(model_name=\"fdtn-ai/Foundation-Sec-8B\", labels=[\n",
    "        \"malware\",\n",
    "        \"phishing\",\n",
    "        \"vulnerability\",\n",
    "        \"incident_response\",\n",
    "        \"threat_intelligence\",\n",
    "        \"compliance\",\n",
    "        \"data_breach\"\n",
    "    ], run_quantized=True)\n",
    "    test_texts = [\n",
    "        \"A critical buffer overflow vulnerability was discovered in the Apache HTTP server that could allow remote code execution.\",\n",
    "        \"Suspicious email attachment containing executable file detected in employee inbox with urgent payment request.\",\n",
    "        \"GDPR compliance audit revealed inadequate data processing consent mechanisms across customer database systems.\",\n",
    "        \"Containment procedures activated following detection of lateral movement in network segment 192.168.1.0/24.\",\n",
    "        \"APT29 group observed using new PowerShell-based persistence mechanism targeting government entities.\"\n",
    "    ]\n",
    "    few_shot_examples = [\n",
    "        (\"SQL injection flaw found in web application login form\", \"vulnerability\"),\n",
    "        (\"Fake Microsoft login page sent to 500 employees\", \"phishing\"),\n",
    "        (\"Ransomware encrypted file server overnight\", \"malware\")\n",
    "    ]\n",
    "    for i, text in enumerate(test_texts, 1):\n",
    "        result = classifier.classify(text, few_shot_examples, return_all_scores=True)\n",
    "        print(f\"{text[:60]}...\")\n",
    "        print(f\"Predicted: {result.predicted_label}\")\n",
    "        print(f\"Probability: {result.raw_probabilities[result.predicted_label]:.3f}\")\n",
    "        print(f\"Confidence: {result.confidence_score:.3f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_security_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe8be6a",
   "metadata": {
    "id": "6fe8be6a"
   },
   "source": [
    "### What the Output Means\n",
    "\n",
    "When you run the classification, you'll see several key metrics:\n",
    "\n",
    "1. **Predicted Category**: The most likely classification\n",
    "   - Examples: \"vulnerability\", \"phishing\", \"malware\"\n",
    "\n",
    "2. **Confidence Score**: How certain the model is (0-1 scale)\n",
    "   - `0.8-1.0`: Very confident\n",
    "   - `0.6-0.8`: Moderately confident  \n",
    "   - `0.4-0.6`: Somewhat uncertain\n",
    "   - `0.0-0.4`: Low confidence (manual review recommended)\n",
    "\n",
    "3. **Probability**: Likelihood of the predicted category (0-1 scale)\n",
    "   - Higher values indicate stronger evidence for that category\n",
    "\n",
    "4. **Top 3 Categories**: Shows alternative classifications\n",
    "   - Useful for edge cases or ambiguous text\n",
    "\n",
    "### Example Output Interpretation\n",
    "```markdown\n",
    "Scenario 1:\n",
    "\n",
    "Text: A critical buffer overflow vulnerability was discovered in t...\n",
    "Predicted Category: vulnerability\n",
    "Confidence: 0.486\n",
    "Probability: 0.664\n",
    "Top 3 categories:\n",
    "   vulnerability: 0.664\n",
    "   malware: 0.201\n",
    "   incident_response: 0.135\n",
    "```\n",
    "\n",
    "**What this tells us:**\n",
    "- The model is 66.4% sure this is about a vulnerability\n",
    "- Confidence is moderate (0.486) - could benefit from more context\n",
    "- Alternative interpretations include malware (20.1%) and incident response (13.5%)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 293.532168,
   "end_time": "2025-06-18T19:08:01.372972",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-18T19:03:07.840804",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
