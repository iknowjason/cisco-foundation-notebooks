{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cisco Foundation Model Quickstart - SageMaker Endpoint\n",
    "This notebook demonstrates basic usage of the Cisco Foundation Security model via SageMaker endpoint.\n",
    "\n",
    "**Note**: Update the configuration variables below to match your deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Update these variables to match your SageMaker deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE THESE VARIABLES TO MATCH YOUR DEPLOYMENT\n",
    "endpoint_name = 'foundation-sec-8b-endpoint'  # Your SageMaker endpoint name\n",
    "aws_region = 'us-east-1'  # Your AWS region\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"Endpoint: {endpoint_name}\")\n",
    "print(f\"Region: {aws_region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers torch --quiet\n",
    "\n",
    "print(\"Required packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import re\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Initialize SageMaker runtime client\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime', region_name=aws_region)\n",
    "\n",
    "print(f\"Connected to SageMaker endpoint: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Configuration\n",
    "Configure the model's text generation behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation arguments for reproducible outputs\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"temperature\": None,  # None means deterministic (temperature=0)\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"do_sample\": False,   # Deterministic sampling\n",
    "    \"use_cache\": True,\n",
    "    # Note: eos_token_id and pad_token_id are handled by the TGI server\n",
    "}\n",
    "\n",
    "print(\"Default generation configuration:\")\n",
    "for key, value in generation_args.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt configuration\n",
    "DEFAULT_SYSTEM_PROMPT = \"You are a cybersecurity expert.\"\n",
    "# The system prompt is for demo purpose.\n",
    "# We have developed a detailed system prompt for general user interaction, which was tested\n",
    "# in internal testing and found that it improved user satisfaction and safety.\n",
    "\n",
    "def inference(request, system_prompt=DEFAULT_SYSTEM_PROMPT, custom_args=None):\n",
    "    \"\"\"Inference function that mimics the local model behavior but uses SageMaker endpoint\"\"\"\n",
    "    \n",
    "    # Handle different request formats\n",
    "    if isinstance(request, str):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": request},\n",
    "        ]\n",
    "    elif isinstance(request, list):\n",
    "        if request[0].get(\"role\") != \"system\":\n",
    "            messages = [{\"role\": \"system\", \"content\": system_prompt}] + request\n",
    "        else:\n",
    "            messages = request\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Request is not well formed. It must be a string or list of dict with correct format.\"\n",
    "        )\n",
    "    \n",
    "    # Format the conversation for the model\n",
    "    formatted_prompt = \"\"\n",
    "    for message in messages:\n",
    "        role = message[\"role\"]\n",
    "        content = message[\"content\"]\n",
    "        if role == \"system\":\n",
    "            formatted_prompt += f\"System: {content}\\n\\n\"\n",
    "        elif role == \"user\":\n",
    "            formatted_prompt += f\"User: {content}\\n\\n\"\n",
    "        elif role == \"assistant\":\n",
    "            formatted_prompt += f\"Assistant: {content}\\n\\n\"\n",
    "    \n",
    "    formatted_prompt += \"Assistant: \"\n",
    "    \n",
    "    # Use custom args if provided, otherwise use defaults\n",
    "    args_to_use = custom_args if custom_args else generation_args\n",
    "    \n",
    "    # Prepare payload for SageMaker endpoint\n",
    "    payload = {\n",
    "        \"inputs\": formatted_prompt,\n",
    "        \"parameters\": args_to_use\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = sagemaker_runtime.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType='application/json',\n",
    "            Body=json.dumps(payload)\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response['Body'].read().decode())\n",
    "        \n",
    "        # Handle different TGI response formats\n",
    "        if isinstance(result, list) and len(result) > 0:\n",
    "            generated_text = result[0].get('generated_text', '')\n",
    "        elif isinstance(result, dict):\n",
    "            generated_text = result.get('generated_text', str(result))\n",
    "        else:\n",
    "            generated_text = str(result)\n",
    "        \n",
    "        # Clean up the response (remove the original prompt if it's included)\n",
    "        if generated_text.startswith(formatted_prompt):\n",
    "            response_text = generated_text[len(formatted_prompt):].strip()\n",
    "        else:\n",
    "            response_text = generated_text.strip()\n",
    "            \n",
    "        # Remove any trailing special tokens\n",
    "        response_text = re.sub(r'<\\|.*?\\|>$', '', response_text).strip()\n",
    "        \n",
    "        return response_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking endpoint: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test the inference function\n",
    "test_response = inference(\"Hello, can you help me with cybersecurity?\")\n",
    "print(\"Test Response:\")\n",
    "print(test_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Basic security question\n",
    "response1 = inference(\"Explain the importance of network segmentation in cybersecurity.\")\n",
    "print(\"=== Network Segmentation Question ===\")\n",
    "display(Markdown(response1))\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Threat analysis with custom generation args\n",
    "custom_args = {\n",
    "    \"max_new_tokens\": 400,\n",
    "    \"temperature\": 0.3,  # Slightly more creative\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "threat_query = \"\"\"Analyze this network activity and identify potential security concerns:\n",
    "\n",
    "- Multiple connections from IP 192.168.1.100 to various external IPs on port 443\n",
    "- Unusual data transfer volumes (10GB outbound in 1 hour)\n",
    "- Connections occurring outside business hours (2-4 AM)\n",
    "- User account: john.doe@company.com\n",
    "\n",
    "What could this indicate and what steps should be taken?\"\"\"\n",
    "\n",
    "response2 = inference(threat_query, custom_args=custom_args)\n",
    "print(\"=== Threat Analysis ===\")\n",
    "display(Markdown(response2))\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Multi-turn conversation\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"What is a zero-day vulnerability?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"A zero-day vulnerability is a security flaw in software that is unknown to the vendor and has no available patch. Attackers can exploit these vulnerabilities before developers can create and distribute fixes.\"},\n",
    "    {\"role\": \"user\", \"content\": \"How can organizations protect themselves against zero-day attacks?\"}\n",
    "]\n",
    "\n",
    "response3 = inference(conversation)\n",
    "print(\"=== Multi-turn Conversation ===\")\n",
    "display(Markdown(response3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Configuration Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with different generation settings for different use cases\n",
    "\n",
    "# Conservative settings for factual responses\n",
    "conservative_args = {\n",
    "    \"max_new_tokens\": 300,\n",
    "    \"temperature\": None,  # Deterministic\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n",
    "# Creative settings for brainstorming\n",
    "creative_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"temperature\": 0.8,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "question = \"List 5 innovative ways to improve cybersecurity awareness in an organization.\"\n",
    "\n",
    "print(\"=== Conservative Response ===\")\n",
    "conservative_response = inference(question, custom_args=conservative_args)\n",
    "display(Markdown(conservative_response))\n",
    "\n",
    "print(\"\\n=== Creative Response ===\")\n",
    "creative_response = inference(question, custom_args=creative_args)\n",
    "display(Markdown(creative_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom System Prompt Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with custom system prompt\n",
    "custom_system_prompt = \"\"\"You are a senior cybersecurity consultant with 15+ years of experience in enterprise security. \n",
    "You provide detailed, actionable advice and always consider both technical and business implications. \n",
    "Your responses should be professional but accessible to both technical and non-technical stakeholders.\"\"\"\n",
    "\n",
    "consultant_query = \"Our company wants to implement zero-trust architecture. What are the key steps and considerations?\"\n",
    "\n",
    "response4 = inference(consultant_query, system_prompt=custom_system_prompt)\n",
    "print(\"=== Senior Consultant Response ===\")\n",
    "display(Markdown(response4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Testing\n",
    "Use this cell to test your own prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own prompt here for testing\n",
    "your_prompt = \"Explain the MITRE ATT&CK framework and its main components.\"\n",
    "\n",
    "your_response = inference(your_prompt)\n",
    "print(\"=== Your Custom Prompt ===\")\n",
    "print(f\"Prompt: {your_prompt}\")\n",
    "print(\"\\nResponse:\")\n",
    "display(Markdown(your_response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
