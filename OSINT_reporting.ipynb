{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9e499b-a8a4-bcd-8e69-c4226e8104cd",
   "metadata": {},
   "source": [
    "# Use Case Description\n",
    "\n",
    "Using public job postings of engineers as OSINT is a common practice. <br>\n",
    "In this use case, we will analyze a hypothetical DevOps engineer job description to uncover potential exploitation scenarios.\n",
    "\n",
    "## Model used for this use case\n",
    "Reasoning Model is well-suited for this use case because the task is complex and requires deep reasoning. In this example, we used the Reasoning Model via SageMaker endpoint.\n",
    "\n",
    "**Note**: Update the configuration variables below to match your deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_config",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Update these variables to match your SageMaker deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these variables to match your deployment\n",
    "endpoint_name = 'foundation-sec-8b-endpoint'\n",
    "aws_region = 'us-east-1'\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"Endpoint: {endpoint_name}\")\n",
    "print(f\"Region: {aws_region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575e36fd-090b-4916-a7bc-1cfa7573c76b",
   "metadata": {},
   "source": [
    "## SetUp\n",
    "\n",
    "The setup uses SageMaker endpoint instead of loading the model locally.\n",
    "\n",
    "### Notice\n",
    "- This notebook uses SageMaker endpoints for scalable inference instead of local model hosting.\n",
    "- The reasoning model is accessed via API calls, providing better resource management and scalability.\n",
    "- Outputs may vary slightly due to the distributed nature of the service, even with consistent parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15989870-5083-42bb-b1e5-4125e452ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import re\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Initialize SageMaker runtime client\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime', region_name=aws_region)\n",
    "\n",
    "print(f\"Connected to SageMaker endpoint: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6accf3-210c-4288-a4ab-a385e4af26ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation arguments for detailed reasoning\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 2048,\n",
    "    \"temperature\": None,  # None means deterministic (temperature=0)\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"do_sample\": False,   # Deterministic sampling for consistent reasoning\n",
    "    \"use_cache\": True\n",
    "}\n",
    "\n",
    "print(\"Generation configuration:\")\n",
    "for key, value in generation_args.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca02e7b7-76e7-44e3-afb0-504e03fe748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(prompt):\n",
    "    \"\"\"Inference function using SageMaker endpoint for reasoning tasks\"\"\"\n",
    "    \n",
    "    # Format the conversation for reasoning model\n",
    "    formatted_prompt = f\"User: {prompt}\\n\\nAssistant: <think>\\n\"\n",
    "    \n",
    "    # Prepare payload for SageMaker endpoint\n",
    "    payload = {\n",
    "        \"inputs\": formatted_prompt,\n",
    "        \"parameters\": generation_args\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = sagemaker_runtime.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType='application/json',\n",
    "            Body=json.dumps(payload)\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response['Body'].read().decode())\n",
    "        \n",
    "        # Handle different TGI response formats\n",
    "        if isinstance(result, list) and len(result) > 0:\n",
    "            generated_text = result[0].get('generated_text', '')\n",
    "        elif isinstance(result, dict):\n",
    "            generated_text = result.get('generated_text', str(result))\n",
    "        else:\n",
    "            generated_text = str(result)\n",
    "        \n",
    "        # Clean up the response (remove the original prompt if it's included)\n",
    "        if generated_text.startswith(formatted_prompt):\n",
    "            response_text = generated_text[len(formatted_prompt):].strip()\n",
    "        else:\n",
    "            response_text = generated_text.strip()\n",
    "        \n",
    "        # Extract thinking part for reasoning models\n",
    "        # Look for content between <think> and </think> or end of text\n",
    "        think_match = re.search(r'<think>(.*?)(?:</think>|$)', response_text, re.DOTALL)\n",
    "        if think_match:\n",
    "            thinking_content = think_match.group(1).strip()\n",
    "            return thinking_content\n",
    "        \n",
    "        # Remove any trailing special tokens\n",
    "        response_text = re.sub(r'<\\|.*?\\|>$', '', response_text).strip()\n",
    "        \n",
    "        return response_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking endpoint: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test the inference function\n",
    "test_response = inference(\"Hello, can you help with OSINT analysis?\")\n",
    "print(\"Test Response:\")\n",
    "print(test_response[:200] + \"...\" if len(test_response) > 200 else test_response)\n",
    "print(\"\\nSageMaker inference function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f5e95e-3a10-454b-8163-8bec830327a9",
   "metadata": {},
   "source": [
    "## Generate a mock job description as OSINT to be analyzed\n",
    "\n",
    "Let's first create a mock job description, which can also be generated using our reasoning model. <br>\n",
    "If you have a specific job description in mind or want to use a real one found online, replace the ```job_description``` variable with your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e408b4-8794-4e73-9a67-bfb15453ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''You are a recruiter at Cisco, hiring a Senior DevOps Engineer for the Security Products team in San Jose. \n",
    "Write a comprehensive and detailed job description for this role in Markdown format.'''\n",
    "\n",
    "print(\"Generating job description using SageMaker endpoint...\")\n",
    "job_description = inference(prompt)\n",
    "print(\"Job description generated successfully!\\n\")\n",
    "display(Markdown(job_description))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e0bd6-a3c4-4482-aa49-aee45f5bc462",
   "metadata": {},
   "source": [
    "### Analyze the job description to find potential exploitation scenarios\n",
    "\n",
    "Let's have the model analyze the job description and generate a report. <br>\n",
    "It's recommended to provide the model with a clear format to follow for consistency and clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a602cc-7507-4e5c-bed1-c169248e29f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_prompt = f'''You are a cybersecurity expert outside Cisco and wants to run some tests against their products only using public information.\n",
    "Based on your knowledge and experience of OSINT, analyze the job description below and write a report of potential exploitation for penetration tests in the following formats.\n",
    "\n",
    "##Summary\n",
    "##Technical Findings\n",
    "##Potential exploitations\n",
    "\n",
    "\n",
    "<Job Description>\n",
    "{job_description}\n",
    "'''\n",
    "\n",
    "print(\"Analyzing job description for OSINT intelligence...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a981c5-e389-4658-8dd4-f81294095b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = inference(analysis_prompt)\n",
    "print(\"OSINT analysis complete!\\n\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced_analysis",
   "metadata": {},
   "source": [
    "## Advanced OSINT Analysis\n",
    "\n",
    "Let's perform additional analysis focusing on specific attack vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced_analysis_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply Chain Attack Analysis\n",
    "supply_chain_prompt = f'''Based on the job description below, analyze potential supply chain attack vectors that could be identified through OSINT. \n",
    "Focus on:\n",
    "1. Third-party dependencies and tools mentioned\n",
    "2. Development workflow vulnerabilities\n",
    "3. Infrastructure dependencies\n",
    "4. Vendor relationships that could be exploited\n",
    "\n",
    "Provide specific recommendations for red team exercises.\n",
    "\n",
    "<Job Description>\n",
    "{job_description}\n",
    "'''\n",
    "\n",
    "print(\"=== SUPPLY CHAIN ATTACK ANALYSIS ===\")\n",
    "supply_chain_analysis = inference(supply_chain_prompt)\n",
    "display(Markdown(supply_chain_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom_analysis_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own job description here for analysis\n",
    "custom_job_description = \"\"\"\n",
    "# Paste your job description here\n",
    "# Example:\n",
    "# Senior Cloud Security Engineer\n",
    "# We are seeking a Senior Cloud Security Engineer to join our team...\n",
    "\"\"\"\n",
    "\n",
    "if custom_job_description.strip() and not custom_job_description.startswith(\"# Paste your\"):\n",
    "    print(\"=== CUSTOM JOB DESCRIPTION ANALYSIS ===\")\n",
    "    \n",
    "    custom_prompt = f'''Analyze this job description from an OSINT and penetration testing perspective.\n",
    "    \n",
    "Focus on:\n",
    "- Cloud security vulnerabilities\n",
    "- Container orchestration risks\n",
    "- API security weaknesses\n",
    "- Identity and access management gaps\n",
    "- Compliance framework exposures\n",
    "\n",
    "Provide actionable intelligence that could be used in authorized security assessments.\n",
    "\n",
    "<Job Description>\n",
    "{custom_job_description}\n",
    "'''\n",
    "    \n",
    "    custom_analysis = inference(custom_prompt)\n",
    "    display(Markdown(custom_analysis))\n",
    "else:\n",
    "    print(\"ðŸ’¡ Add your own job description in the custom_job_description variable above to analyze it!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
